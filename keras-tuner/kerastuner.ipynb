{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13]\n",
    "#Create dummy variables\n",
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)\n",
    "## Concatenate the Data Frames\n",
    "\n",
    "X=pd.concat([X,geography,gender],axis=1)\n",
    "\n",
    "## Drop Unnecessary columns\n",
    "X=X.drop(['Geography','Gender'],axis=1)\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.1-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=84f1dc6ba1508e3999166d49f6a08e9716ef959c74f87cc7dc6a5d34cd3ebc67\n",
      "  Stored in directory: c:\\users\\mahima\\appdata\\local\\pip\\cache\\wheels\\23\\9d\\42\\5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.1 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Using cached keras-tuner-1.0.2.tar.gz (62 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from keras-tuner) (20.9)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from keras-tuner) (1.19.5)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting terminaltables\n",
      "  Using cached terminaltables-3.1.0.tar.gz (12 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from keras-tuner) (0.4.4)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.59.0-py2.py3-none-any.whl (74 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from keras-tuner) (2.25.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from keras-tuner) (1.5.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from keras-tuner) (0.24.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from packaging->keras-tuner) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from requests->keras-tuner) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from requests->keras-tuner) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from requests->keras-tuner) (4.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mahima\\anaconda3\\envs\\newtf\\lib\\site-packages (from scikit-learn->keras-tuner) (2.1.0)\n",
      "Building wheels for collected packages: keras-tuner, future, terminaltables\n",
      "  Building wheel for keras-tuner (setup.py): started\n",
      "  Building wheel for keras-tuner (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-py3-none-any.whl size=78936 sha256=13f353376e7d6c82e7327455ef227678d07fa35f16f6fc49cf15ebc840f2e168\n",
      "  Stored in directory: c:\\users\\mahima\\appdata\\local\\pip\\cache\\wheels\\f9\\42\\e3\\73f763092b16b23350dbc5b7d9b6220bdbff2944ffcc2c612b\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=a8e2c8710f03f89401239d5597e45b59884a3641f9df3d91604fc20220463300\n",
      "  Stored in directory: c:\\users\\mahima\\appdata\\local\\pip\\cache\\wheels\\6e\\9c\\ed\\4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
      "  Building wheel for terminaltables (setup.py): started\n",
      "  Building wheel for terminaltables (setup.py): finished with status 'done'\n",
      "  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15355 sha256=b55d5d6f0fe6ddb3d8644bc7a67217192931043f969ccbd3d2717ee8a12de64f\n",
      "  Stored in directory: c:\\users\\mahima\\appdata\\local\\pip\\cache\\wheels\\86\\1b\\58\\c23af2fe683acd8edc15d5a1268f0242be1ff2cf827fe34737\n",
      "Successfully built keras-tuner future terminaltables\n",
      "Installing collected packages: tqdm, terminaltables, tabulate, future, keras-tuner\n",
      "Successfully installed future-0.18.2 keras-tuner-1.0.2 tabulate-0.8.9 terminaltables-3.1.0 tqdm-4.59.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "# it fit the model\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='project1',\n",
    "    project_name='Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()\n",
    "# its give the summary of everthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 05s]\n",
      "val_accuracy: 0.7975000143051147\n",
      "\n",
      "Best val_accuracy So Far: 0.7975000143051147\n",
      "Total elapsed time: 00h 03m 23s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=5,\n",
    "             validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in project1\\Churn\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 10\n",
      "units_0: 160\n",
      "units_1: 480\n",
      "learning_rate: 0.01\n",
      "units_2: 160\n",
      "units_3: 256\n",
      "units_4: 64\n",
      "units_5: 448\n",
      "units_6: 32\n",
      "units_7: 32\n",
      "units_8: 32\n",
      "units_9: 32\n",
      "Score: 0.7975000143051147\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 12\n",
      "units_0: 480\n",
      "units_1: 288\n",
      "learning_rate: 0.001\n",
      "units_2: 512\n",
      "units_3: 288\n",
      "units_4: 32\n",
      "units_5: 224\n",
      "units_6: 160\n",
      "units_7: 448\n",
      "units_8: 480\n",
      "units_9: 224\n",
      "units_10: 32\n",
      "units_11: 32\n",
      "Score: 0.7975000143051147\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 352\n",
      "units_1: 288\n",
      "learning_rate: 0.01\n",
      "units_2: 384\n",
      "units_3: 448\n",
      "units_4: 256\n",
      "units_5: 320\n",
      "units_6: 96\n",
      "units_7: 96\n",
      "units_8: 288\n",
      "units_9: 64\n",
      "units_10: 512\n",
      "units_11: 128\n",
      "Score: 0.7975000143051147\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 13\n",
      "units_0: 320\n",
      "units_1: 384\n",
      "learning_rate: 0.01\n",
      "units_2: 256\n",
      "units_3: 480\n",
      "units_4: 256\n",
      "units_5: 64\n",
      "units_6: 96\n",
      "units_7: 416\n",
      "units_8: 352\n",
      "units_9: 416\n",
      "units_10: 320\n",
      "units_11: 448\n",
      "units_12: 32\n",
      "Score: 0.7975000143051147\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 64\n",
      "units_1: 320\n",
      "learning_rate: 0.0001\n",
      "units_2: 32\n",
      "units_3: 32\n",
      "units_4: 32\n",
      "units_5: 32\n",
      "Score: 0.7933333317438761\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseTuner.get_best_hyperparameters of <kerastuner.tuners.randomsearch.RandomSearch object at 0x000001D8CC0080B8>>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.get_best_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
